{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e59a6b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'load'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    100\u001b[0m writer \u001b[38;5;241m=\u001b[39m SummaryWriter(experiment_name) \n\u001b[0;32m    102\u001b[0m \u001b[38;5;66;03m# model_path = 'weights/Morph2Diff/unified/iter/' + experiment_name + \"_\" + \"unfreezecnnon5_transforms\" #Diff_RangerLars_lr_1e3_4096_epochs_60_batch_32_vgg16_warmup_10k_cosine_bin_1_2'\u001b[39;00m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;66;03m# if not os.path.exists(model_path):\u001b[39;00m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;66;03m#     os.makedirs(model_path)\u001b[39;00m\n\u001b[1;32m--> 106\u001b[0m gen_model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgen_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    107\u001b[0m \u001b[43m                \u001b[49m\u001b[43mdisc_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    108\u001b[0m \u001b[43m                \u001b[49m\u001b[43mgen_optimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    109\u001b[0m \u001b[43m                \u001b[49m\u001b[43mdisc_optimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    110\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrec_criterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    111\u001b[0m \u001b[43m                \u001b[49m\u001b[43madv_criterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    112\u001b[0m \u001b[43m                \u001b[49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLAMBDA_REC\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    113\u001b[0m \u001b[43m                \u001b[49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLAMBDA_ADV\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    114\u001b[0m \u001b[43m                \u001b[49m\u001b[43mdata_loaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    115\u001b[0m \u001b[43m                \u001b[49m\u001b[43mdataset_sizes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    116\u001b[0m \u001b[43m                \u001b[49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mNUM_EPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    117\u001b[0m \u001b[43m                \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[43m                \u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\ran\\ContextEncoder4Inpainting\\train.py:39\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(gen_model, disc_model, gen_optimizer, disc_optimizer, rec_criterion, adv_criterion, lambda_rec, lambda_adv, data_loaders, dataset_sizes, num_epochs, device, writer)\u001b[0m\n\u001b[0;32m     34\u001b[0m running_gadv_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m#validate(gen_model, disc_model, rec_criterion, adv_criterion, lambda_rec, lambda_adv, data_loaders['valid'], dataset_sizes['valid'], epoch, device, writer)\u001b[39;00m\n\u001b[1;32m---> 39\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m tqdm(data_loaders[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m]):\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;66;03m# import pdb\u001b[39;00m\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;66;03m# pdb.set_trace()\u001b[39;00m\n\u001b[0;32m     42\u001b[0m     orig_image \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124morig_image\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     43\u001b[0m     real_parts \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124morig_parts\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[1;32m~\\.conda\\envs\\ran_thesis_py38\\lib\\site-packages\\tqdm\\std.py:1158\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1155\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[0;32m   1157\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1158\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[0;32m   1159\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[0;32m   1160\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[0;32m   1161\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[1;32m~\\.conda\\envs\\ran_thesis_py38\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:521\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    519\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    520\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[1;32m--> 521\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    522\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    523\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    524\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    525\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32m~\\.conda\\envs\\ran_thesis_py38\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:561\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    559\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    560\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 561\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    562\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    563\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data)\n",
      "File \u001b[1;32m~\\.conda\\envs\\ran_thesis_py38\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[1;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32m~\\.conda\\envs\\ran_thesis_py38\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[1;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32m~\\ran\\ContextEncoder4Inpainting\\dataset.py:98\u001b[0m, in \u001b[0;36mImagesDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[38;5;66;03m# plt.imshow(np.transpose(masked_image.numpy(), (1, 2, 0)))\u001b[39;00m\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;66;03m# plt.show()\u001b[39;00m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmasking_method \u001b[38;5;241m==\u001b[39m MaskingMethod\u001b[38;5;241m.\u001b[39mRandomBlock:\n\u001b[1;32m---> 98\u001b[0m     masked_image, orig_parts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mask_random_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmasking_method \u001b[38;5;241m==\u001b[39m MaskingMethod\u001b[38;5;241m.\u001b[39mRandomRegion:\n\u001b[0;32m    100\u001b[0m     masked_image, orig_parts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mask_random_region(image)\n",
      "File \u001b[1;32m~\\ran\\ContextEncoder4Inpainting\\dataset.py:67\u001b[0m, in \u001b[0;36mImagesDataset._mask_random_block\u001b[1;34m(self, image)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m mask_low_idx, mask_high_idx, mask_low_idy, mask_high_idy \u001b[38;5;129;01min\u001b[39;00m ids:\n\u001b[0;32m     66\u001b[0m     masked_image[:, mask_low_idx:mask_high_idx, mask_low_idy:mask_high_idy] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 67\u001b[0m orig_parts \u001b[38;5;241m=\u001b[39m \u001b[43mImageChops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubtract\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmasked_image\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m masked_image, orig_parts\n",
      "File \u001b[1;32m~\\.conda\\envs\\ran_thesis_py38\\lib\\site-packages\\PIL\\ImageChops.py:205\u001b[0m, in \u001b[0;36msubtract\u001b[1;34m(image1, image2, scale, offset)\u001b[0m\n\u001b[0;32m    193\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msubtract\u001b[39m(image1, image2, scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m, offset\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m    194\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;124;03m    Subtracts two images, dividing the result by scale and adding the offset.\u001b[39;00m\n\u001b[0;32m    196\u001b[0m \u001b[38;5;124;03m    If omitted, scale defaults to 1.0, and offset to 0.0.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;124;03m    :rtype: :py:class:`~PIL.Image.Image`\u001b[39;00m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 205\u001b[0m     \u001b[43mimage1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m()\n\u001b[0;32m    206\u001b[0m     image2\u001b[38;5;241m.\u001b[39mload()\n\u001b[0;32m    207\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m image1\u001b[38;5;241m.\u001b[39m_new(image1\u001b[38;5;241m.\u001b[39mim\u001b[38;5;241m.\u001b[39mchop_subtract(image2\u001b[38;5;241m.\u001b[39mim, scale, offset))\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'load'"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from datetime import datetime\n",
    "import os\n",
    "import random\n",
    "\n",
    "import config as cfg\n",
    "from dataset import *\n",
    "from train import *\n",
    "from model import *\n",
    "import matplotlib.pyplot as plt\n",
    "if cfg.ENABLE_TENSORBOARD:\n",
    "    from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "if cfg.FIXED_RANDOM:\n",
    "    torch.manual_seed(cfg.RANDOM_SEED)\n",
    "    np.random.seed(cfg.RANDOM_SEED)\n",
    "    random.seed(cfg.RANDOM_SEED)\n",
    "\n",
    "\n",
    "if cfg.USE_GPU:\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    torch.cuda.empty_cache()\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(device)\n",
    "\n",
    "\n",
    "train_set = ImagesDataset(images_dir_path=cfg.DATASET_PATH, \n",
    "                set_type=SetType.TrainSet, \n",
    "                masking_method=eval(\"MaskingMethod.\"+cfg.MASKING_METHOD), \n",
    "                image_dim_size=cfg.IMAGE_SIZE, \n",
    "                mask_dim_size=cfg.MASK_SIZE,\n",
    "                mask_max_pixels=cfg.RANDOM_REGION_MASK_MAX_PIXELS,\n",
    "                transform=transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                ]))\n",
    "\n",
    "if cfg.SHOW_IMAGE:\n",
    "    for image in train_set:\n",
    "        try:\n",
    "            data = image\n",
    "            plt.imshow(np.transpose(data[\"masked_image\"].numpy(), (1, 2, 0)))\n",
    "            plt.show()\n",
    "            plt.imshow(np.transpose(data[\"orig_parts\"].numpy(), (1, 2, 0)))\n",
    "            plt.show()\n",
    "        except KeyboardInterrupt:\n",
    "            exit()\n",
    "\n",
    "valid_set = ImagesDataset(images_dir_path=cfg.DATASET_PATH, \n",
    "                set_type=SetType.ValidSet, \n",
    "                masking_method=eval(\"MaskingMethod.\"+cfg.MASKING_METHOD), \n",
    "                image_dim_size=cfg.IMAGE_SIZE, \n",
    "                mask_dim_size=cfg.MASK_SIZE,\n",
    "                mask_max_pixels=cfg.RANDOM_REGION_MASK_MAX_PIXELS,\n",
    "                transform=transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                ]))\n",
    "                \n",
    "\n",
    "dataset_sizes = {\n",
    "    'train' : len(train_set),\n",
    "    'valid' : len(valid_set)\n",
    "}\n",
    "   \n",
    "data_loaders = {\n",
    "    'train': DataLoader(train_set, batch_size=cfg.BATCH_SIZE, num_workers=cfg.NUM_OF_WORKERS_DATALOADER, pin_memory=True, shuffle=True, drop_last=True),\n",
    "    'valid': DataLoader(valid_set, batch_size=cfg.BATCH_SIZE, num_workers=cfg.NUM_OF_WORKERS_DATALOADER, pin_memory=True, shuffle=False, drop_last=True)\n",
    "}\n",
    "\n",
    "if cfg.MASKING_METHOD == \"CentralRegion\":\n",
    "    gen_model = GeneratorNet(output_full_image=True) #False\n",
    "    disc_model = DiscriminatorNet(output_full_image=True) #False\n",
    "else:\n",
    "    gen_model = GeneratorNet(output_full_image=True)\n",
    "    disc_model = DiscriminatorNet(output_full_image=True)\n",
    "\n",
    "\n",
    "# pretrained model loading\n",
    "if cfg.ENABLE_PRETRAINED_MODEL_LOAD:\n",
    "    gen_enc_model_file = os.path.join(cfg.PRETRIANED_MODEL_PATH, \"gen_encoder_weights.pt\")\n",
    "    gen_model.load_pretrained_encoder(gen_enc_model_file)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "if cfg.USE_GPU:\n",
    "    gen_model.to(device)\n",
    "    disc_model.to(device)\n",
    "\n",
    "gen_optimizer = torch.optim.Adam(gen_model.parameters(), lr=cfg.GEN_LR) #betas=())\n",
    "disc_optimizer = torch.optim.Adam(disc_model.parameters(), lr=cfg.DISC_LR, betas=(cfg.DISC_BETA1, cfg.DISC_BETA2))\n",
    "\n",
    "rec_criterion = nn.MSELoss()\n",
    "adv_criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "params = [cfg.BATCH_SIZE,\n",
    "cfg.NUM_EPOCHS,\n",
    "cfg.GEN_LR,\n",
    "cfg.DISC_LR,\n",
    "cfg.DISC_BETA1,\n",
    "cfg.DISC_BETA2,\n",
    "cfg.LAMBDA_REC,\n",
    "cfg.LAMBDA_ADV]\n",
    "\n",
    "params_str = '_'.join([str(p) for p in params])\n",
    "now = datetime.now()\n",
    "date_time = now.strftime(\"%m_%d_%Y_%H_%M_%S\")\n",
    "experiment_name = 'logs/' + cfg.DATASET_SELECT + '/experiment_' + date_time + 'masking' + cfg.MASKING_METHOD + '_' + params_str\n",
    "\n",
    "if cfg.ENABLE_TENSORBOARD:\n",
    "    writer = SummaryWriter(experiment_name) \n",
    "else:\n",
    "    writer = None\n",
    "\n",
    "# model_path = 'weights/Morph2Diff/unified/iter/' + experiment_name + \"_\" + \"unfreezecnnon5_transforms\" #Diff_RangerLars_lr_1e3_4096_epochs_60_batch_32_vgg16_warmup_10k_cosine_bin_1_2'\n",
    "# if not os.path.exists(model_path):\n",
    "#     os.makedirs(model_path)\n",
    "\n",
    "gen_model = train_model(gen_model, \n",
    "                disc_model, \n",
    "                gen_optimizer,\n",
    "                disc_optimizer,\n",
    "                rec_criterion,\n",
    "                adv_criterion,\n",
    "                cfg.LAMBDA_REC,\n",
    "                cfg.LAMBDA_ADV,\n",
    "                data_loaders, \n",
    "                dataset_sizes,\n",
    "                cfg.NUM_EPOCHS,\n",
    "                device, \n",
    "                writer)\n",
    "\n",
    "print(\"saving model\")\n",
    "# save model\n",
    "if cfg.ENABLE_MODEL_SAVE:\n",
    "    gen_enc_model_file = os.path.join(cfg.MODEL_SAVE_PATH, \"gen_encoder_weights.pt\")\n",
    "    torch.save(gen_model.get_encoder().state_dict(), gen_enc_model_file)\n",
    "    gen_dec_model_file = os.path.join(cfg.MODEL_SAVE_PATH, \"gen_decoder_weights.pt\")\n",
    "    torch.save(gen_model.get_encoder().state_dict(), gen_enc_model_file)\n",
    "    disc_model_file = os.path.join(cfg.MODEL_SAVE_PATH, \"disc_weights.pt\")\n",
    "    torch.save(disc_model.state_dict(), disc_model_file)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f6afdb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
