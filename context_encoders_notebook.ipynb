{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71d1c03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixing random in order to enable reproduction\n",
      "Setting device for pytorch\n",
      "Device:  cuda:0\n",
      "resizing images to 128\n",
      "Creating training set\n",
      "Creating validation set\n",
      "Creating models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/87 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (1): BatchNorm2d(64, eps=0.8, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): LeakyReLU(negative_slope=0.2)\n",
      "  (3): Conv2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (4): BatchNorm2d(64, eps=0.8, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (5): LeakyReLU(negative_slope=0.2)\n",
      "  (6): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (7): BatchNorm2d(128, eps=0.8, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (8): LeakyReLU(negative_slope=0.2)\n",
      "  (9): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (10): BatchNorm2d(256, eps=0.8, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (11): LeakyReLU(negative_slope=0.2)\n",
      "  (12): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (13): BatchNorm2d(512, eps=0.8, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (14): LeakyReLU(negative_slope=0.2)\n",
      "  (15): Conv2d(512, 4000, kernel_size=(1, 1), stride=(1, 1))\n",
      ")\n",
      "Sequential(\n",
      "  (0): ConvTranspose2d(4000, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (1): BatchNorm2d(512, eps=0.8, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): ReLU()\n",
      "  (3): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (4): BatchNorm2d(256, eps=0.8, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (5): ReLU()\n",
      "  (6): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (7): BatchNorm2d(128, eps=0.8, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (8): ReLU()\n",
      "  (9): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (10): BatchNorm2d(64, eps=0.8, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (11): ReLU()\n",
      "  (12): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (13): Tanh()\n",
      ")\n",
      "Doing arrangements to run & log model...\n",
      "Setting up experiment logging on Tensorboard\n",
      "Runing training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 87/87 [00:32<00:00,  2.68it/s]\n",
      "  0%|                                                                                           | 0/22 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Training | Disc Loss: 0.6514865550012402, | Gen Loss: 0.21226607537820114, | gRec Loss: 0.2118695836719357, | gAdv Loss: 0.1257870763910812, |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 22/22 [00:08<00:00,  2.58it/s]\n",
      "  0%|                                                                                           | 0/87 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation | Disc Loss: 0.7277823767878793, | Gen Loss: 0.3503485321998596, | gRec Loss: 0.3501596843654459, | gAdv Loss: 0.5390027707273309, |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|████████████████████████████████████████████████████▊                             | 56/87 [00:09<00:05,  5.21it/s]"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from datetime import datetime\n",
    "import os\n",
    "import random\n",
    "\n",
    "import config as cfg\n",
    "from dataset import *\n",
    "from train import *\n",
    "from model import *\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if cfg.ENABLE_TENSORBOARD:\n",
    "    from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "if cfg.FIXED_RANDOM:\n",
    "    print(\"Fixing random in order to enable reproduction\")\n",
    "    torch.manual_seed(cfg.RANDOM_SEED)\n",
    "    np.random.seed(cfg.RANDOM_SEED)\n",
    "    random.seed(cfg.RANDOM_SEED)\n",
    "\n",
    "\n",
    "print(\"Setting device for pytorch\")\n",
    "if cfg.USE_GPU:\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    torch.cuda.empty_cache()\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(\"Device: \", device)\n",
    "\n",
    "\n",
    "# setting transforms\n",
    "transforms_list = []\n",
    "if cfg.TO_RESIZE:\n",
    "    print(\"resizing images to\", cfg.RESIZE_DIM)\n",
    "    transforms_list.append(transforms.Resize((cfg.RESIZE_DIM, cfg.RESIZE_DIM)))\n",
    "transforms_list.append(transforms.ToTensor())\n",
    "if cfg.TO_NORMALIZE:\n",
    "    transforms_list.append(transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)))#(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])) #(0.5, 0.5, 0.5), (0.5, 0.5, 0.5)))\n",
    "\n",
    "\n",
    "print(\"Creating training set\")\n",
    "\n",
    "\n",
    "train_set = ImagesDataset(images_dir_path=cfg.DATASET_PATH, \n",
    "                set_type=SetType.TrainSet, \n",
    "                masking_method=eval(\"MaskingMethod.\"+cfg.MASKING_METHOD), \n",
    "                image_dim_size=cfg.IMAGE_SIZE, \n",
    "                mask_dim_size=cfg.MASK_SIZE,\n",
    "                mask_max_pixels=cfg.RANDOM_REGION_MASK_MAX_PIXELS,\n",
    "                overlap=cfg.MASK_OVERLAP,\n",
    "                transform=transforms.Compose(transforms_list))\n",
    "\n",
    "if cfg.SHOW_IMAGE:\n",
    "    print(\"Debug only: showing training set examples (with masks)\")\n",
    "    for image in train_set:\n",
    "        try:\n",
    "            data = image\n",
    "            plt.imshow(np.transpose(data[\"masked_image\"].numpy(), (1, 2, 0)))\n",
    "            plt.show()\n",
    "            plt.imshow(np.transpose(data[\"orig_parts\"].numpy(), (1, 2, 0)))\n",
    "            plt.show()\n",
    "        except KeyboardInterrupt:\n",
    "            exit()\n",
    "\n",
    "print(\"Creating validation set\")\n",
    "valid_set = ImagesDataset(images_dir_path=cfg.DATASET_PATH, \n",
    "                set_type=SetType.ValidSet, \n",
    "                masking_method=eval(\"MaskingMethod.\"+cfg.MASKING_METHOD), \n",
    "                image_dim_size=cfg.IMAGE_SIZE, \n",
    "                mask_dim_size=cfg.MASK_SIZE,\n",
    "                mask_max_pixels=cfg.RANDOM_REGION_MASK_MAX_PIXELS,\n",
    "                overlap=cfg.MASK_OVERLAP,\n",
    "                transform=transforms.Compose(transforms_list))\n",
    "                \n",
    "\n",
    "dataset_sizes = {\n",
    "    'train' : len(train_set),\n",
    "    'valid' : len(valid_set)\n",
    "}\n",
    "   \n",
    "data_loaders = {\n",
    "    'train': DataLoader(train_set, batch_size=cfg.BATCH_SIZE, num_workers=cfg.NUM_OF_WORKERS_DATALOADER, pin_memory=True, shuffle=True, drop_last=True),\n",
    "    'valid': DataLoader(valid_set, batch_size=cfg.BATCH_SIZE, num_workers=cfg.NUM_OF_WORKERS_DATALOADER, pin_memory=True, shuffle=False, drop_last=True)\n",
    "}\n",
    "\n",
    "print(\"Creating models\")\n",
    "if cfg.MASKING_METHOD == \"CentralRegion\":\n",
    "    gen_model = GeneratorNet(output_full_image=False, output_size=cfg.MASK_SIZE) #False\n",
    "    disc_model = DiscriminatorNet(input_full_image=False, input_size=cfg.MASK_SIZE) #False\n",
    "else:\n",
    "    gen_model = GeneratorNet(output_full_image=True)\n",
    "    disc_model = DiscriminatorNet(input_full_image=True)\n",
    "\n",
    "\n",
    "# pretrained model loading\n",
    "if cfg.APPLY_GAUSSIAN_WEIGHT_INIT:\n",
    "    gen_model.apply(weights_init)\n",
    "    disc_model.apply(weights_init)\n",
    "\n",
    "if cfg.ENABLE_PRETRAINED_MODEL_LOAD:\n",
    "    print(\"Loading pretrained model (for enabling transfer learning)\")\n",
    "    if cfg.DATASET_SELECT == \"photo\":\n",
    "        gen_enc_model_file = os.path.join(cfg.PRETRAINED_MODEL_PATH, \"CentralRegion_64_gen_encoder_weights.pt\")\n",
    "        #gen_dec_model_file = os.path.join(cfg.PRETRAINED_MODEL_PATH, \"CentralRegion_64_gen_decoder_weights.pt\")\n",
    "        #disc_model_file = os.path.join(cfg.PRETRAINED_MODEL_PATH, \"CentralRegion_64_disc_weights.pt\")\n",
    "        gen_model.load_pretrained_encoder(gen_enc_model_file)\n",
    "        #gen_model.load_pretrained_decoder(gen_dec_model_file)\n",
    "        #disc_model.load_model(disc_model_file)\n",
    "    else:\n",
    "        gen_enc_model_file = os.path.join(cfg.PRETRAINED_MODEL_PATH, \"RandomRegion_gen_encoder_weights.pt\")\n",
    "        gen_model.load_pretrained_encoder(gen_enc_model_file)\n",
    "\n",
    "\n",
    "print(\"Doing arrangements to run & log model...\")\n",
    "if cfg.USE_GPU:\n",
    "    gen_model.to(device)\n",
    "    disc_model.to(device)\n",
    "\n",
    "gen_optimizer = torch.optim.Adam(gen_model.parameters(), lr=cfg.GEN_LR) #betas=())\n",
    "disc_optimizer = torch.optim.Adam(disc_model.parameters(), lr=cfg.DISC_LR, betas=(cfg.DISC_BETA1, cfg.DISC_BETA2))\n",
    "\n",
    "rec_criterion = nn.MSELoss()\n",
    "adv_criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "params = [cfg.BATCH_SIZE,\n",
    "cfg.NUM_EPOCHS,\n",
    "cfg.GEN_LR,\n",
    "cfg.DISC_LR,\n",
    "cfg.DISC_BETA1,\n",
    "cfg.DISC_BETA2,\n",
    "cfg.LAMBDA_REC,\n",
    "cfg.LAMBDA_ADV]\n",
    "\n",
    "params_str = '_'.join([str(p) for p in params])\n",
    "now = datetime.now()\n",
    "date_time = now.strftime(\"%m_%d_%Y_%H_%M_%S\")\n",
    "experiment_name = 'logs/' + cfg.DATASET_SELECT + '/experiment_' + date_time + 'masking' + cfg.MASKING_METHOD + '_' + params_str\n",
    "\n",
    "if cfg.ENABLE_TENSORBOARD:\n",
    "    print(\"Setting up experiment logging on Tensorboard\")\n",
    "    writer = SummaryWriter(experiment_name) \n",
    "else:\n",
    "    writer = None\n",
    "\n",
    "# model_path = 'weights/Morph2Diff/unified/iter/' + experiment_name + \"_\" + \"unfreezecnnon5_transforms\" #Diff_RangerLars_lr_1e3_4096_epochs_60_batch_32_vgg16_warmup_10k_cosine_bin_1_2'\n",
    "# if not os.path.exists(model_path):\n",
    "#     os.makedirs(model_path)\n",
    "\n",
    "print(\"Runing training...\")\n",
    "gen_model, disc_model = train_model(gen_model, \n",
    "                disc_model, \n",
    "                gen_optimizer,\n",
    "                disc_optimizer,\n",
    "                rec_criterion,\n",
    "                adv_criterion,\n",
    "                cfg.LAMBDA_REC,\n",
    "                cfg.LAMBDA_ADV,\n",
    "                data_loaders, \n",
    "                dataset_sizes,\n",
    "                cfg.NUM_EPOCHS,\n",
    "                device, \n",
    "                writer)\n",
    "\n",
    "print(\"Saving model\")\n",
    "\n",
    "if cfg.MASKING_METHOD == \"CentralRegion\":\n",
    "    save_prefix = \"CentralRegion_\" + str(cfg.MASK_SIZE)\n",
    "else:\n",
    "    save_prefix = cfg.MASKING_METHOD\n",
    "\n",
    "# save model\n",
    "if cfg.ENABLE_MODEL_SAVE:\n",
    "    gen_enc_model_file = os.path.join(cfg.MODEL_SAVE_PATH, save_prefix + \"_gen_encoder_weights.pt\")\n",
    "    torch.save(gen_model.get_encoder().state_dict(), gen_enc_model_file)\n",
    "    gen_dec_model_file = os.path.join(cfg.MODEL_SAVE_PATH, save_prefix + \"_gen_decoder_weights.pt\")\n",
    "    torch.save(gen_model.get_decoder().state_dict(), gen_dec_model_file)\n",
    "    disc_model_file = os.path.join(cfg.MODEL_SAVE_PATH, save_prefix + \"_disc_weights.pt\")\n",
    "    torch.save(disc_model.state_dict(), disc_model_file)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ae1eac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
